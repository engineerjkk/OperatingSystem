# 컴퓨터에서의 플랫폼 : Operating System
## 운영체제의 역사
* 다른 응용프로그램이 실행될 수 있는 환경을 제공
* A program that controls the execution of application programs
* An interface between applications and hardware

* Main objectives of an OS : 운영체제가 추구하는 목적
- convenience : 편리성
- efficiency : CPU, memory
- ability to evolve : 추가적인 하드웨어를 받을 수 있는 확장성, 새로운 환경에 진화

- 1970년 중반부터 PC가 등장한다. 그 이전의 중대형 컴퓨터였다.
중대형 컴퓨터는 잘 아는사람이 썼지만 PC는 잘 몰라도 작업하기 위해서 사용한다. 내부동작원리를 잘 이해하게 하고 쓴다면 사람들이 편리하게 쓰기 어렵다.
-> 따라서 보다 사람들이 쉽게 사용하는 것이 중요한것이 운영체제의 목적이었다.  

![image](https://user-images.githubusercontent.com/76835313/132607984-891ce910-4c85-424a-9992-cc044f7d9eca.png)
1. CPU는 Execution hardware에 있으며, 프로그램들은 Main memory에 적재된다.
2. 이러한 CPU과 프로그램들은 bus를 통해서 연결되어있게 된다.
3. Instruction Set Architecture 아래서 하드웨어 구성이며 이 하드웨어를 제대로 동작하게 하는 것이 Operating System의 역할이 된다.
4. 즉, 하드웨어를 구동시켜주고 다른 Application이 실행할 수 있도록, 라이브러리, 유틸리티를 제공한다.   

         The hardware and software used in providing applications to a user can be viewed
         in a layered or hierarchical fashion, as depicted in Figure 2.1 . The user of those
         applications, the end user, generally is not concerned with the details of computer
         hardware. Thus, the end user views a computer system in terms of a set of applications.
         An application can be expressed in a programming language and is developed
         by an application programmer. If one were to develop an application program as a
         set of machine instructions that is completely responsible for controlling the computer
         hardware, one would be faced with an overwhelmingly complex undertaking.
         To ease this chore, a set of system programs is provided. Some of these programs
         are referred to as utilities, or library programs. These implement frequently used
         functions that assist in program creation, the management of files, and the control of
         I/O devices. A programmer will make use of these facilities in developing an application,
         and the application, while it is running, will invoke the utilities to perform
         certain functions. The most important collection of system programs comprises the
         OS. The OS masks the details of the hardware from the programmer and provides
         the programmer with a convenient interface for using the system. It acts as mediator,
         making it easier for the programmer and for application programs to access and
         use those facilities and services.


![image](https://user-images.githubusercontent.com/76835313/132608558-21a847d5-626a-4c60-8b2d-0ab322ab41da.png)

API : 응용프로그램에서는 하부 계층에 있는 라이브러리의 기능들을 호출함으로써 하드웨어적 기능을 활용한다.
-> UNIX에서는 System Call이라고 부른다.   
         Figure 2.1 also indicates three key interfaces in a typical computer system:

         • Instruction set architecture (ISA) : The ISA defines the repertoire of machine
         language instructions that a computer can follow. This interface is the boundary
         between hardware and software. Note that both application programs
         and utilities may access the ISA directly. For these programs, a subset of the
         instruction repertoire is available (user ISA). The OS has access to additional
         machine language instructions that deal with managing system resources
         (system ISA).

         • Application binary interface (ABI) : The ABI defines a standard for binary
         portability across programs. The ABI defines the system call interface to
         the operating system and the hardware resources and services available in a
         system through the user ISA.

         • Application programming interface (API) : The API gives a program access
         to the hardware resources and services available in a system through the user
         ISA supplemented with high-level language (HLL) library calls. Any system
         calls are usually performed through libraries. Using an API enables application
         software to be ported easily, through recompilation, to other systems that
         support the same API.


![image](https://user-images.githubusercontent.com/76835313/132608580-3adb1741-61c1-4cb9-91b3-c6663e5b4c67.png)
1. 프로그램을 실행 시켜주어야한다.
2. I/O 디바이스를 접근하게 해준다.
3. 운영체제에 의해서 파일들을 관리한다
4. 시스템의 자원 : CPU, Memory
5. 프로그램 개발환경 지원
6. 에러가 날 경우 중단시킨다. 
7. 회계 -> 개인으로 쓰는건 이런 개념이 없지만 서버들은 얼마만큼의 CPU를 얼마동안 썼는지, 메모리 얼마썼는지 비용을 계산해 청구한다.  

         Briefly, the OS typically provides services in the following areas:

         • Program development: The OS provides a variety of facilities and services,
         such as editors and debuggers, to assist the programmer in creating programs.
         Typically, these services are in the form of utility programs that, while not
         strictly part of the core of the OS, are supplied with the OS and are referred to
         as application program development tools.

         • Program execution: A number of steps need to be performed to execute a
         program. Instructions and data must be loaded into main memory, I/O devices
         and files must be initialized, and other resources must be prepared. The OS
         handles these scheduling duties for the user.

         • Access to I/O devices: Each I/O device requires its own peculiar set of instructions
         or control signals for operation. The OS provides a uniform interface
         that hides these details so that programmers can access such devices using simple
         reads and writes.

         • Controlled access to files: For file access, the OS must reflect a detailed understanding
         of not only the nature of the I/O device (disk drive, tape drive) but
         also the structure of the data contained in the files on the storage medium.
         In the case of a system with multiple users, the OS may provide protection
         mechanisms to control access to the files.

         • System access: For shared or public systems, the OS controls access to the
         system as a whole and to specific system resources. The access function must
         provide protection of resources and data from unauthorized users and must
         resolve conflicts for resource contention.

         • Error detection and response: A variety of errors can occur while a computer
         system is running. These include internal and external hardware errors, such
         as a memory error, or a device failure or malfunction; and various software
         errors, such as division by zero, attempt to access forbidden memory location,
         and inability of the OS to grant the request of an application. In each case,
         the OS must provide a response that clears the error condition with the least
         impact on running applications. The response may range from ending the program
         that caused the error, to retrying the operation, to simply reporting the
         error to the application.

         • Accounting: A good OS will collect usage statistics for various resources and
         monitor performance parameters such as response time. On any system, this
         information is useful in anticipating the need for future enhancements and in
         tuning the system to improve performance. On a multiuser system, the information
         can be used for billing purposes.



![image](https://user-images.githubusercontent.com/76835313/132608721-15ae8d0e-b9b1-4b5d-a98f-59f02070deb1.png)
* 데이터를 옮기로 처리하기 위한 자원들의 집합
* 리소스들을 관리한다. 

         A computer is a set of resources for the movement, storage, and processing of data
         and for the control of these functions. The OS is responsible for managing these
         resources.

![image](https://user-images.githubusercontent.com/76835313/132608830-dc516cf6-a6f5-4e47-8531-d7c717658deb.png)
1. 운영체제는 기본적으로 소프트웨어이다. 프로그램이 동작하는 것과 똑같이 동작한다. 
2. 프로그램들의 집합이며, 결국 CPU에서 실행되어야만 프로그램을 컴퓨터에서 제공할 수 있다. 
3. 운영체제가 다시 CPU에서 실행되려하면 CPU에 의해서 이루어진다. 운영체제의 기능은 CPU에서 실행될때 기능하고 필요없으면 제어를 포기하고 다른 응용프로그램들이 CPU에서 실행 될 수 있도록한다. 

         The OS, as a control mechanism is unusual in two respects:

         • The OS functions in the same way as ordinary computer software; that is, it is
         a program or suite of programs executed by the processor.

         • The OS frequently relinquishes control and must depend on the processor to
         allow it to regain control.

         Like other computer programs, the OS provides instructions for the processor.
         The key difference is in the intent of the program. The OS directs the processor
         in the use of the other system resources and in the timing of its execution of other
         programs. But in order for the processor to do any of these things, it must cease
         executing the OS program and execute other programs. Thus, the OS relinquishes
         control for the processor to do some “useful” work and then resumes control long
         enough to prepare the processor to do the next piece of work. The mechanisms
         involved in all this should become clear as the chapter proceeds.



![image](https://user-images.githubusercontent.com/76835313/132609011-5d918bc0-9fe0-4c22-926f-e25f7612743f.png)  

         Figure 2.2 suggests the main resources that are managed by the OS. A portion
         of the OS is in main memory. This includes the kernel , or nucleus , which contains
         the most frequently used functions in the OS and, at a given time, other portions
         of the OS currently in use. The remainder of main memory contains user programs
         and data. The memory management hardware in the processor and the OS jointly
         control the allocation of main memory, as we shall see. The OS decides when an I/O
         device can be used by a program in execution and controls access to and use of files.
         The processor itself is a resource, and the OS must determine how much processor
         time is to be devoted to the execution of a particular user program. In the case of a
         multiple-processor system, this decision must span all of the processors.


![image](https://user-images.githubusercontent.com/76835313/132609132-c506f077-cc6c-433c-97b9-8be8aac0cd78.png)
1. 대부분의 중요한 운영체제는 시간에 따라서 진화해 왔다.
2. 새로운 서비스를 제공해야 운영체제가 살아남는다. -> 적자생존

         A major OS will evolve over time for a number of reasons:

         • Hardware upgrades plus new types of hardware: For example, early versions
         of UNIX and the Macintosh OS did not employ a paging mechanism because
         they were run on processors without paging hardware. Subsequent versions
         of these operating systems were modified to exploit paging capabilities. Also,
         the use of graphics terminals and page-mode terminals instead of line-at-a time
         scroll mode terminals affects OS design. For example, a graphics terminal
         typically allows the user to view several applications at the same time through
         “windows” on the screen. This requires more sophisticated support in the OS.

         • New services: In response to user demand or in response to the needs of system
         managers, the OS expands to offer new services. For example, if it is found
         to be difficult to maintain good performance for users with existing tools, new
         measurement and control tools may be added to the OS.

         • Fixes: Any OS has faults. These are discovered over the course of time and
         fixes are made. Of course, the fix may introduce new faults.

         The need to change an OS regularly places certain requirements on its design.
         An obvious statement is that the system should be modular in construction, with
         clearly defined interfaces between the modules, and that it should be well documented.
         For large programs, such as the typical contemporary OS, what might be
         referred to as straightforward modularization is inadequate [DENN80a]. That is,
         much more must be done than simply partitioning a program into modules. We
         return to this topic later in this chapter.


![image](https://user-images.githubusercontent.com/76835313/132609515-71dd78f7-4f90-4579-99b0-4d22a1fbafcf.png)
1. 처음엔 순차적으로 처리했다.
2. CPU, memory를 효율적으로 사용하기 위해 Simple Batch Systems
3. Multiprogrammed Batch Systems
4. Time Sharing Systems -> Clinets의 요청을 받기 위해

         In attempting to understand the key requirements for an OS and the significance of the major features of a contemporary OS, 
         it is useful to consider how operating systems have evolved over the years.        



![image](https://user-images.githubusercontent.com/76835313/132609636-3bbb752a-5bcf-4460-8dac-9fb414aade4a.png)  
1. 처음에는 운영체제가 없었다. 사용자가 직접 하드웨어를 조작하여 실행시켰다. 
2. 컴퓨터에 직접 연결돼있는것 : 콘솔  
-> display lights, switches, keyboard, printer로 이루어져있었고 이거를 실행시켰다.   
3. 차례로 컴퓨터에 접근할 수 있었다. 

하지만 이로인한 문제는 사용자들이 컴퓨터를 사용하기 위해 얼마나 컴퓨터를 사용할지 신청서에다가 사인해서 제출해야 했다. 

         With the earliest computers, from the late 1940s to the mid-1950s, the programmer
         interacted directly with the computer hardware; there was no OS. These computers
         were run from a console consisting of display lights, toggle switches, some form of
         input device, and a printer. Programs in machine code were loaded via the input
         device (e.g., a card reader). If an error halted the program, the error condition was
         indicated by the lights. If the program proceeded to a normal completion, the output
         appeared on the printer.

         These early systems presented two main problems:

         • Scheduling : Most installations used a hardcopy sign-up sheet to reserve computer
         time. Typically, a user could sign up for a block of time in multiples of a
         half hour or so. A user might sign up for an hour and finish in 45 minutes; this
         would result in wasted computer processing time. On the other hand, the user
         might run into problems, not finish in the allotted time, and be forced to stop
         before resolving the problem.

         • Setup time: A single program, called a job , could involve loading the compiler
         plus the high-level language program (source program) into memory,
         saving the compiled program (object program) and then loading and linking
         together the object program and common functions. Each of these steps could
         involve mounting or dismounting tapes or setting up card decks. If an error
         occurred, the hapless user typically had to go back to the beginning of the
         setup sequence. Thus, a considerable amount of time was spent just in setting
         up the program to run.

         This mode of operation could be termed serial processing , reflecting the fact
         that users have access to the computer in series. Over time, various system software
         tools were developed to attempt to make serial processing more efficient. These
         include libraries of common functions, linkers, loaders, debuggers, and I/O driver
         routines that were available as common software for all users.


![image](https://user-images.githubusercontent.com/76835313/132610822-d1066124-df74-43b1-a350-5b883fae7179.png)  
 
         Early computers were very expensive, and therefore it was important to maximize
         processor utilization. The wasted time due to scheduling and setup time was
         unacceptable.

         To improve utilization, the concept of a batch OS was developed. It appears
         that the first batch OS (and the first OS of any kind) was developed in the mid-1950s
         by General Motors for use on an IBM 701 [WEIZ81]. The concept was subsequently
         refined and implemented on the IBM 704 by a number of IBM customers. By the
         early 1960s, a number of vendors had developed batch operating systems for their
         computer systems. IBSYS, the IBM OS for the 7090/7094 computers, is particularly
         notable because of its widespread influence on other systems.

         The central idea behind the simple batch-processing scheme is the use of a
         piece of software known as the monitor . With this type of OS, the user no longer has
         direct access to the processor. Instead, the user submits the job on cards or tape to a
         computer operator, who batches the jobs together sequentially and places the entire
         batch on an input device, for use by the monitor. Each program is constructed to
         branch back to the monitor when it completes processing, at which point the monitor
         automatically begins loading the next program.

 
![image](https://user-images.githubusercontent.com/76835313/132611849-4fe3e347-e7b6-4af5-b596-af3597c5ecb7.png)  
  
1. resident는 상주한다는 뜻이된다. 거주민을 resident. 의사로서 레지던트는 수련이기에 병원에서 상주한다.  

         Monitor point of view: The monitor controls the sequence of events. For this
         to be so, much of the monitor must always be in main memory and available
         for execution ( Figure 2.3 ). That portion is referred to as the resident monitor .
         The rest of the monitor consists of utilities and common functions that are
         loaded as subroutines to the user program at the beginning of any job that
         requires them. The monitor reads in jobs one at a time from the input device
         (typically a card reader or magnetic tape drive). As it is read in, the current job
         is placed in the user program area, and control is passed to this job. When the
         job is completed, it returns control to the monitor, which immediately reads
         in the next job. The results of each job are sent to an output device, such as a
         printer, for delivery to the user.


![image](https://user-images.githubusercontent.com/76835313/132612325-2bb6128e-7f8f-4844-b1f5-ac5834bbf958.png)  
1. 메모리에 있는 명령어를 실행한다. 응용프로그램의 코드. 운영체제의 기능.  
2. CPU가 user 프로그램을 실행하는데 언제까지 실행하냐 -> } 를 만날 때 까지 or return을 만날때까지하면 운영체제 종료할 때 까지 한다.   
3. CPU가 실행되는 권한을 모니터에게 되돌려준다.   

         Processor point of view: At a certain point, the processor is executing instructions
         from the portion of main memory containing the monitor. These
         instructions cause the next job to be read into another portion of main
         memory. Once a job has been read in, the processor will encounter a branch
         instruction in the monitor that instructs the processor to continue execution
         at the start of the user program. The processor will then execute the instructions
         in the user program until it encounters an ending or error condition.
         Either event causes the processor to fetch its next instruction from the monitor
         program. Thus the phrase “control is passed to a job” simply means that
         the processor is now fetching and executing instructions in a user program,
         and “control is returned to the monitor” means that the processor is now
         fetching and executing instructions from the monitor program.


![image](https://user-images.githubusercontent.com/76835313/132612498-6aa0c0a6-7de1-44cf-af04-340b90a270cd.png)  

         The monitor performs a scheduling function: A batch of jobs is queued up,
         and jobs are executed as rapidly as possible, with no intervening idle time. The monitor
         improves job setup time as well. With each job, instructions are included in a
         primitive form of job control language (JCL) . This is a special type of programming
         language used to provide instructions to the monitor. A simple example is that of a
         user submitting a program written in the programming language FORTRAN plus
         some data to be used by the program. All FORTRAN instructions and data are on a
         separate punched card or a separate record on tape. In addition to FORTRAN and
         data lines, the job includes job control instructions, which are denoted by the beginning


![image](https://user-images.githubusercontent.com/76835313/132612909-7ebd2d7f-db9a-44e8-9174-2f478c3e97b6.png) 

         The monitor performs a scheduling function: A batch of jobs is queued up,
         and jobs are executed as rapidly as possible, with no intervening idle time. The monitor
         improves job setup time as well. With each job, instructions are included in a
         primitive form of job control language (JCL) . This is a special type of programming
         language used to provide instructions to the monitor. A simple example is that of a
         user submitting a program written in the programming language FORTRAN plus
         some data to be used by the program. All FORTRAN instructions and data are on a
         separate punched card or a separate record on tape. In addition to FORTRAN and
         data lines, the job includes job control instructions, which are denoted by the beginning


![image](https://user-images.githubusercontent.com/76835313/132612980-f429a5fa-c605-4c8b-8a8d-880223f1a1a7.png)  
잡 스탭은 잡 컨트롤    

         The monitor, or batch OS, is simply a computer program. It relies on the ability
         of the processor to fetch instructions from various portions of main memory to
         alternately seize and relinquish control. Certain other hardware features are also
         desirable:

         • Memory protection: While the user program is executing, it must not alter the
         memory area containing the monitor. If such an attempt is made, the processor
         hardware should detect an error and transfer control to the monitor. The
         monitor would then abort the job, print out an error message, and load in the
         next job.

         • Timer: A timer is used to prevent a single job from monopolizing the system.
         The timer is set at the beginning of each job. If the timer expires, the user program
         is stopped, and control returns to the monitor.

         • Privileged instructions : Certain machine level instructions are designated privileged
         and can be executed only by the monitor. If the processor encounters
         such an instruction while executing a user program, an error occurs causing
         control to be transferred to the monitor. Among the privileged instructions
         are I/O instructions, so that the monitor retains control of all I/O devices. This
         prevents, for example, a user program from accidentally reading job control
         instructions from the next job. If a user program wishes to perform I/O, it must
         request that the monitor perform the operation for it.

         Interrupts : Early computer models did not have this capability. This feature
         gives the OS more flexibility in relinquishing control to and regaining control
         from user programs.


![image](https://user-images.githubusercontent.com/76835313/132613037-5062dfd9-9aad-44b5-bd45-923e42836770.png)
1.Memory
2. Timer
3. 특별한 목적으로 만들어진 기계어
4. Interrupts : 여러개의 응용프로그램이 실행되더라고 급한걸 먼저처리함으로써 전체적으로 조화롭게 대처하면서 실행시키는 것이다.  

         Considerations of memory protection and privileged instructions lead to the
         concept of modes of operation. A user program executes in a user mode , in which
         certain areas of memory are protected from the user’s use and in which certain
         instructions may not be executed. The monitor executes in a system mode, or what
         has come to be called kernel mode , in which privileged instructions may be executed
         and in which protected areas of memory may be accessed.

         Of course, an OS can be built without these features. But computer vendors
         quickly learned that the results were chaos, and so even relatively primitive batch
         operating systems were provided with these hardware features.

![image](https://user-images.githubusercontent.com/76835313/132613383-296a21ce-75ac-4715-8dbc-a5a74cb13d19.png)
1. 유저모드
2. 커널모드
-> 운영체제는 모드를 통해 안전하게 관리한다.
-> 유저모드에서 할당된 영역은 유저의 access에서 보호가 된다. 다른 사용자들은 그 메모리 영역을 접근하면 안된다.
-> 커널모드에서는 모니터가 실행되는건 커널모드에서 실행된다. 그 다음에 사용자의 메모리영역이라하더라도 때에따라 접근할 수 있어.

         Considerations of memory protection and privileged instructions lead to the
         concept of modes of operation. A user program executes in a user mode , in which
         certain areas of memory are protected from the user’s use and in which certain
         instructions may not be executed. The monitor executes in a system mode, or what
         has come to be called kernel mode , in which privileged instructions may be executed
         and in which protected areas of memory may be accessed.

         Of course, an OS can be built without these features. But computer vendors
         quickly learned that the results were chaos, and so even relatively primitive batch
         operating systems were provided with these hardware features.


![image](https://user-images.githubusercontent.com/76835313/132613578-77ccab92-4da8-440a-ba8c-5b45174687a7.png)

         With a batch OS, processor time alternates between execution of user programs
         and execution of the monitor. There have been two sacrifices: Some main
         memory is now given over to the monitor and some processor time is consumed by
         the monitor. Both of these are forms of overhead. Despite this overhead, the simple
         batch system improves utilization of the computer.


![image](https://user-images.githubusercontent.com/76835313/132613698-034845ae-59ac-4bac-b38a-ff84226ce358.png)  
file에서 하나의 recode를 읽는데 15us가 걸렸다. 100개 메모리는 1us이다. 그러면 이 작업을 하나의 프로그램이 했다면 전체적으로 31us이다. 
CPU는 종종 놀고있다. 입출력은 메모리단에 비해면 메우 느리다.  

         Even with the automatic job sequencing provided by a simple batch OS, the processor
         is often idle. The problem is that I/O devices are slow compared to the processor.
         Figure 2.4 details a representative calculation. The calculation concerns a program
         that processes a file of records and performs, on average, 100 machine instructions
         per record. In this example, the computer spends over 96% of its time waiting for
         I/O devices to finish transferring data to and from the file.



![image](https://user-images.githubusercontent.com/76835313/132613870-9fc320b0-44c6-4ce7-93a2-7c28b07156c7.png)
* 순차적으로 실행되는것 uni 프로그램이다.  

         Figure 2.5a illustrates this situation, where we have a single program, referred to as uniprogramming. 
         The processor spends a certain amount of time executing, until it reaches an I/O instruction.
         It must then wait until that I/O instruction concludes before proceeding.


![image](https://user-images.githubusercontent.com/76835313/132613909-275feb01-3330-4fd8-a292-429f46954638.png)
* 그래서 멀티프로그래밍을 도입한다.  

         This inefficiency is not necessary. We know that there must be enough
         memory to hold the OS (resident monitor) and one user program. Suppose that
         there is room for the OS and two user programs. When one job needs to wait for
         I/O, the processor can switch to the other job, which is likely not waiting for I/O
         ( Figure 2.5b ).


![image](https://user-images.githubusercontent.com/76835313/132613969-f1034b57-07f2-435e-97fe-2681626af46d.png)
         Furthermore, we might expand memory to hold three, four, or more
         programs and switch among all of them ( Figure 2.5c ). The approach is known as
         multiprogramming , or multitasking . It is the central theme of modern operating
         systems.
![image](https://user-images.githubusercontent.com/76835313/132614030-5f262381-b612-4ef0-bd7a-f6ad6abc62ad.png)
         To illustrate the benefit of multiprogramming, we give a simple example.
         Consider a computer with 250 Mbytes of available memory (not used by the OS),
         a disk, a terminal, and a printer. Three programs, JOB1, JOB2, and JOB3, are
         submitted for execution at the same time, with the attributes listed in Table 2.1 .
         We assume minimal processor requirements for JOB2 and JOB3 and continuous
         disk and printer use by JOB3. For a simple batch environment, these jobs will be
         executed in sequence. Thus, JOB1 completes in 5 minutes. JOB2 must wait until
         the 5 minutes are over and then completes 15 minutes after that. JOB3 begins after
         20 minutes and completes at 30 minutes from the time it was initially submitted.
![image](https://user-images.githubusercontent.com/76835313/132614138-997ede3b-0e22-4b42-a120-13a206882ad3.png)
         Device-by-device utilization is illustrated in
         Figure 2.6a . It is evident that there is gross underutilization for all resources when
         averaged over the required 30-minute time period.

         Now suppose that the jobs are run concurrently under a multiprogramming
         OS. Because there is little resource contention between the jobs, all three can run
         in nearly minimum time while coexisting with the others in the computer (assuming
         that JOB2 and JOB3 are allotted enough processor time to keep their input
         and output operations active). JOB1 will still require 5 minutes to complete, but at
         the end of that time, JOB2 will be one-third finished and JOB3 half finished. All
         three jobs will have finished within 15 minutes. The improvement is evident when
         examining the multiprogramming column of Table 2.2 , obtained from the histogram
         shown in Figure 2.6b .

![image](https://user-images.githubusercontent.com/76835313/132614419-fe3318d5-16f7-418b-8a43-bf6167b6fada.png)
         The average resource utilization, throughput, and response times are shown in the
         uniprogramming column of Table 2.2 .


![image](https://user-images.githubusercontent.com/76835313/132614702-8d82ad1a-4363-4d1d-805e-224fd75ca112.png)
* Time sharing System으로 발전했다. 
* 여기서 Time은 CPU시간을 의미한다. 
* interactive jobs. 상호작용. 그거보고 실행하며 되돌려받으며 컴퓨터를 사용한다. 
* CPU가 조금식 나눠쓰며 공유한다.

         Just as multiprogramming allows the processor to handle multiple batch jobs
         at a time, multiprogramming can also be used to handle multiple interactive jobs. In
         this latter case, the technique is referred to as time sharing , because processor time is
         shared among multiple users. In a time-sharing system, multiple users simultaneously
         access the system through terminals, with the OS interleaving the execution of each
         user program in a short burst or quantum of computation. Thus, if there are n users
         actively requesting service at one time, each user will only see on the average 1/ n
         of the effective computer capacity, not counting OS overhead. However, given the
         relatively slow human reaction time, the response time on a properly designed system
         should be similar to that on a dedicated computer.

![image](https://user-images.githubusercontent.com/76835313/132614960-9d511d50-cd08-4081-bb6e-ebc86b578ae6.png)
* 응답시간을 최소화하는 것이 목적이다. 컴퓨터의 자원이 아주 충분히 잘 발전했기에 사용자가 더 편리하게, 지연되지않는것을 목적으로한다. 
         Both batch processing and time sharing use multiprogramming. The key
         differences are listed in Table 2.3 .


![image](https://user-images.githubusercontent.com/76835313/132615080-4a5fde6d-32f9-4868-b403-c92d377699a6.png)
* CTSS 
* Time Slicing : 시분할 시스템
-> 시스템의 클럭을 통해서한다. 

         One of the first time-sharing operating systems to be developed was the
         Compatible Time-Sharing System (CTSS) [CORB62], developed at MIT by a
         group known as Project MAC (Machine-Aided Cognition, or Multiple-Access
         Computers). The system was first developed for the IBM 709 in 1961 and later
         transferred to an IBM 7094.

         Compared to later systems, CTSS is primitive. The system ran on a computer
         with 32,000 36-bit words of main memory, with the resident monitor consuming 5000
         of that. When control was to be assigned to an interactive user, the user’s program
         and data were loaded into the remaining 27,000 words of main memory. A program
         was always loaded to start at the location of the 5000th word; this simplified
         both the monitor and memory management. A system clock generated interrupts
         at a rate of approximately one every 0.2 seconds. At each clock interrupt, the OS
         regained control and could assign the processor to another user. This technique is
         known as time slicing . Thus, at regular time intervals, the current user would be
         preempted and another user loaded in. To preserve the old user program status for
         later resumption, the old user programs and data were written out to disk before the
         new user programs and data were read in. Subsequently, the old user program code
         and data were restored in main memory when that program was next given a turn.


![image](https://user-images.githubusercontent.com/76835313/132615166-9730b2cb-5fdd-4adb-ac41-3c933288a78d.png)
         To minimize disk traffic, user memory was only written out when the incoming
         program would overwrite it. This principle is illustrated in Figure 2.7 . Assume that
         there are four interactive users with the following memory requirements, in words:

         • JOB1: 15,000
         • JOB2: 20,000
         JOB3: 5000
         • JOB4: 10,000

         Initially, the monitor loads JOB1 and transfers control to it (a). Later, the
         monitor decides to transfer control to JOB2. Because JOB2 requires more memory
         than JOB1, JOB1 must be written out first, and then JOB2 can be loaded (b).
         Next, JOB3 is loaded in to be run. However, because JOB3 is smaller than JOB2,
         a portion of JOB2 can remain in memory, reducing disk write time (c). Later, the
         monitor decides to transfer control back to JOB1. An additional portion of JOB2
         must be written out when JOB1 is loaded back into memory (d). When JOB4 is
         loaded, part of JOB1 and the portion of JOB2 remaining in memory are retained
         (e). At this point, if either JOB1 or JOB2 is activated, only a partial load will be
         required. In this example, it is JOB2 that runs next. This requires that JOB4 and the
         remaining resident portion of JOB1 be written out and that the missing portion of
         JOB2 be read in (f).


![image](https://user-images.githubusercontent.com/76835313/132615231-c892289b-4ca2-4ffb-aa3d-339633d282d9.png)
* 운영체제는 수많은 프로그램들을 실행시켜주는 소프트웨어기때문에 복잡한 소프트웨어이다. 
* 이때 주요한 개념이 프로세스, 메모리관리, 메모리보호, CPU와 disk의 스케줄링, 자원관리 등을 관리하기위해 발전해왔다.
         Operating systems are among the most complex pieces of software ever developed.
         This reflects the challenge of trying to meet the difficult and in some cases
         competing objectives of convenience, efficiency, and ability to evolve. [DENN80a]
         proposes that there have been four major theoretical advances in the development
         of operating systems:

         • Processes
         • Memory management
         • Information protection and security
         • Scheduling and resource management

         Each advance is characterized by principles, or abstractions, developed to
         meet difficult practical problems. Taken together, these five areas span many of
         the key design and implementation issues of modern operating systems. The brief
         review of these five areas in this section serves as an overview of much of the rest
         of the text.


![image](https://user-images.githubusercontent.com/76835313/132615311-c68440ae-12c3-48ec-bc3b-54f60aa6e8d0.png)
-> 프로그램을 실행시키면 프로세스가 된다. 운영체제는 프로세스를 관리한다.   
         Central to the design of operating systems is the concept of process. This term was
         first used by the designers of Multics in the 1960s [DALE68]. It is a somewhat
         more general term than job. Many definitions have been given for the term process ,
         including
         • A program in execution
         • An instance of a program running on a computer
         • The entity that can be assigned to and executed on a processor
         • A unit of activity characterized by a single sequential thread of execution, a
         current state, and an associated set of system resources


![image](https://user-images.githubusercontent.com/76835313/132615378-b793a034-a046-4c1e-9d68-e88c39c10ce5.png)
프로세스의 발전 : 멀티프로그래밍 배치, time sharing, real-time

          Three major lines of computer system development created problems in timing
          and synchronization that contributed to the development of the concept of the
          process: multiprogramming batch operation, time sharing, and real-time transaction
          systems. As we have seen, multiprogramming was designed to keep the processor
          and I/O devices, including storage devices, simultaneously busy to achieve maximum
          efficiency. The key mechanism is this: In response to signals indicating the
          completion of I/O transactions, the processor is switched among the various programs
          residing in main memory.

          A second line of development was general-purpose time sharing. Here, the
          key design objective is to be responsive to the needs of the individual user and yet,
          for cost reasons, be able to support many users simultaneously. These goals are
          compatible because of the relatively slow reaction time of the user. For example,
          if a typical user needs an average of 2 seconds of processing time per minute, then
          close to 30 such users should be able to share the same system without noticeable
          interference. Of course, OS overhead must be factored into such calculations.

          A third important line of development has been real-time transaction processing
          systems. In this case, a number of users are entering queries or updates against a
          database. An example is an airline reservation system. The key difference between
          the transaction processing system and the time-sharing system is that the former
          is limited to one or a few applications, whereas users of a time-sharing system can
          engage in program development, job execution, and the use of various applications.
          In both cases, system response time is paramount.



















